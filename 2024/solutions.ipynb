{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(filename: str):\n",
    "    with open(f\"{filename}.txt\") as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2031679)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_input(\"1\")\n",
    "\n",
    "data = np.array([[int(num) for num in line.split(\"   \")] for line in data.split(\"\\n\")])\n",
    "\n",
    "data_1 = data[:, 0]\n",
    "data_2 = data[:, 1]\n",
    "\n",
    "# order the data\n",
    "data_1 = np.sort(data_1)\n",
    "data_2 = np.sort(data_2)\n",
    "\n",
    "sum(abs(data_2 - data_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(19678534)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_input(\"1\")\n",
    "\n",
    "data = np.array([[int(num) for num in line.split(\"   \")] for line in data.split(\"\\n\")])\n",
    "\n",
    "data_1 = data[:, 0]\n",
    "data_2 = data[:, 1]\n",
    "\n",
    "similarity_score = 0\n",
    "\n",
    "for num in data_1:\n",
    "    similarity_score += num * sum(data_2 == num)\n",
    "\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[int(num) for num in line.split(\" \")] for line in read_input(\"2\").split(\"\\n\")]\n",
    "\n",
    "def is_safe(report):\n",
    "    sign = np.sign(report[1] - report[0])\n",
    "    valid = True\n",
    "    for idx in range(1, len(report)):\n",
    "        diff = report[idx] - report[idx - 1]\n",
    "        if sign != np.sign(diff):\n",
    "            valid = False\n",
    "            break\n",
    "\n",
    "        if diff == 0 or abs(diff) > 3:\n",
    "            valid = False\n",
    "            break\n",
    "    \n",
    "    return valid, idx\n",
    "\n",
    "n_safe = 0\n",
    "\n",
    "for report in data:\n",
    "    valid, idx = is_safe(report)\n",
    "    if valid:\n",
    "        n_safe += 1\n",
    "    \n",
    "n_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[int(num) for num in line.split(\" \")] for line in read_input(\"2\").split(\"\\n\")]\n",
    "\n",
    "def is_safe(report):\n",
    "    sign = np.sign(report[1] - report[0])\n",
    "    valid = True\n",
    "    for idx in range(1, len(report)):\n",
    "        diff = report[idx] - report[idx - 1]\n",
    "        if sign != np.sign(diff):\n",
    "            valid = False\n",
    "            break\n",
    "\n",
    "        if diff == 0 or abs(diff) > 3:\n",
    "            valid = False\n",
    "            break\n",
    "    \n",
    "    return valid, idx\n",
    "\n",
    "n_safe = 0\n",
    "\n",
    "for report in data:\n",
    "    valid, idx = is_safe(report)\n",
    "    if valid:\n",
    "        n_safe += 1\n",
    "    else:\n",
    "        for rem_idx in range(len(report)):\n",
    "            cut_report = report[:rem_idx] + report[rem_idx + 1:]\n",
    "            valid, _ = is_safe(cut_report)\n",
    "            if valid:\n",
    "                n_safe += 1\n",
    "                break\n",
    "    \n",
    "n_safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161289189"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_input(\"3\")\n",
    "\n",
    "valid_mul = re.compile(r\"mul\\(\\d+,\\d+\\)\")\n",
    "\n",
    "multiplications = valid_mul.findall(data)\n",
    "\n",
    "total = 0\n",
    "\n",
    "for mul in multiplications:\n",
    "    nums = [int(num) for num in mul[4:-1].split(\",\")]\n",
    "    total += nums[0] * nums[1]\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83595109"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_input(\"3\")\n",
    "\n",
    "valid_mul = r\"mul\\(\\d+,\\d+\\)\"\n",
    "valid_do = r\"do\\(\\)\"\n",
    "valid_dont = r\"don't\\(\\)\"\n",
    "valid_all = f\"{valid_mul}|{valid_do}|{valid_dont}\"\n",
    "\n",
    "re_mul = re.compile(valid_mul)\n",
    "re_do = re.compile(valid_do)\n",
    "re_dont = re.compile(valid_dont)\n",
    "re_all = re.compile(valid_all)\n",
    "\n",
    "operations = re_all.findall(data)\n",
    "\n",
    "total = 0\n",
    "do_state = True\n",
    "\n",
    "for op in operations:\n",
    "    if re_mul.match(op) and do_state:\n",
    "        nums = [int(num) for num in op[4:-1].split(\",\")]\n",
    "        total += nums[0] * nums[1]\n",
    "    elif re_do.match(op):\n",
    "        do_state = True\n",
    "    elif re_dont.match(op):\n",
    "        do_state = False\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[letter for letter in line] for line in read_input(\"4\").split(\"\\n\")])\n",
    "\n",
    "valid_words = [\"XMAS\", \"SAMX\"]\n",
    "re_valid_words = [re.compile(word) for word in valid_words]\n",
    "\n",
    "total_hits = 0\n",
    "\n",
    "def check_line(line):\n",
    "    hits = 0\n",
    "    for re_word in re_valid_words:\n",
    "        hits += len(re_word.findall(line))\n",
    "    return hits\n",
    "\n",
    "# horizontal\n",
    "for row in data:\n",
    "    line = \"\".join(row)\n",
    "    total_hits += check_line(line)\n",
    "\n",
    "# vertical\n",
    "for col in range(data.shape[1]):\n",
    "    line = \"\".join(data[:, col])\n",
    "    total_hits += check_line(line)\n",
    "\n",
    "# diagonal top left to bottom right\n",
    "for idx in range(data.shape[0]):\n",
    "    line = \"\".join(data.diagonal(idx))\n",
    "    total_hits += check_line(line)\n",
    "    if idx != 0:\n",
    "        line = \"\".join(data.diagonal(-idx))\n",
    "        total_hits += check_line(line)\n",
    "\n",
    "# diagonal top right to bottom left\n",
    "for idx in range(data.shape[0]):\n",
    "    line = \"\".join(np.fliplr(data).diagonal(idx))\n",
    "    total_hits += check_line(line)\n",
    "    if idx != 0:\n",
    "        line = \"\".join(np.fliplr(data).diagonal(-idx))\n",
    "        total_hits += check_line(line)\n",
    "\n",
    "total_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[letter for letter in line] for line in read_input(\"4\").split(\"\\n\")])\n",
    "\n",
    "valid_diags = [\"MAS\", \"SAM\"]\n",
    "n_valid_X_MAS = 0\n",
    "\n",
    "def check_valid_X_MAS(window):\n",
    "    if not \"\".join(window.diagonal()) in valid_diags:\n",
    "        return False\n",
    "    if not \"\".join(np.fliplr(window).diagonal()) in valid_diags:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# loop over data with 3x3 window\n",
    "for row in range(data.shape[0] - 2):\n",
    "    for col in range(data.shape[1] - 2):\n",
    "        window = data[row:row + 3, col:col + 3]\n",
    "        if check_valid_X_MAS(window):\n",
    "            n_valid_X_MAS += 1\n",
    "\n",
    "n_valid_X_MAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4185"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules, updates = read_input(\"5\").split(\"\\n\\n\")\n",
    "\n",
    "rules = rules.split(\"\\n\")\n",
    "updates = updates.split(\"\\n\")\n",
    "\n",
    "# parse rules\n",
    "rules = [rule.split(\"|\") for rule in rules]\n",
    "rules = {frozenset([rule[0], rule[1]]): [rule[0], rule[1]] for rule in rules}\n",
    "\n",
    "# parse updates\n",
    "updates = [update.split(\",\") for update in updates]\n",
    "\n",
    "sum_middle_pages = 0\n",
    "\n",
    "# check updates\n",
    "for update in updates:\n",
    "    valid = True\n",
    "    for combo in combinations(update, 2):\n",
    "        rule = rules.get(frozenset(combo))\n",
    "        if rule:\n",
    "            idx_first = update.index(rule[0])\n",
    "            idx_second = update.index(rule[1])\n",
    "            if idx_first > idx_second:\n",
    "                valid = False\n",
    "                break\n",
    "    \n",
    "    if valid:\n",
    "        sum_middle_pages += int(update[len(update) // 2])\n",
    "\n",
    "sum_middle_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules, updates = read_input(\"5\").split(\"\\n\\n\")\n",
    "\n",
    "rules = rules.split(\"\\n\")\n",
    "updates = updates.split(\"\\n\")\n",
    "\n",
    "# parse rules\n",
    "rules = [rule.split(\"|\") for rule in rules]\n",
    "rules = {frozenset([rule[0], rule[1]]): [rule[0], rule[1]] for rule in rules}\n",
    "\n",
    "# parse updates\n",
    "updates = [update.split(\",\") for update in updates]\n",
    "\n",
    "incorrect_updates = []\n",
    "\n",
    "# check updates\n",
    "for update in updates:\n",
    "    valid = True\n",
    "    for combo in combinations(update, 2):\n",
    "        rule = rules.get(frozenset(combo))\n",
    "        if rule:\n",
    "            idx_first = update.index(rule[0])\n",
    "            idx_second = update.index(rule[1])\n",
    "            if idx_first > idx_second:\n",
    "                valid = False\n",
    "                incorrect_updates.append(update)\n",
    "                break\n",
    "\n",
    "# We know that the set of pages in updates == the set of pages in rules\n",
    "# I assume that for each page, there is a rule for it and every other page\n",
    "\n",
    "# So then for each set of pages (update) there is a unique correct order of pages\n",
    "\n",
    "def build_order(update):\n",
    "    # Build order by counting nr of rules which have a page as first\n",
    "    nr_of_firsts = []\n",
    "\n",
    "    for page in update:\n",
    "        # Generate keys\n",
    "        keys = [frozenset([page, other_page]) for other_page in update if other_page != page]\n",
    "        firsts = sum([rules.get(key)[0] == page for key in keys])\n",
    "        nr_of_firsts.append(firsts)\n",
    "\n",
    "    # Should be unique (no two pages have the same nr of firsts)\n",
    "    assert len(set(nr_of_firsts)) == len(nr_of_firsts)\n",
    "    # order all_pages by nr_of_firsts\n",
    "    all_pages_ordered = [page for _, page in sorted(zip(nr_of_firsts, update), reverse=True)]\n",
    "    return all_pages_ordered\n",
    "\n",
    "# reorder invalid updates\n",
    "sum_middle_pages = 0\n",
    "\n",
    "for update in incorrect_updates:\n",
    "    reordered_update = []\n",
    "    orderd_update = build_order(update)\n",
    "    for page in orderd_update:\n",
    "        if page in update:\n",
    "            reordered_update.append(page)\n",
    "\n",
    "    assert len(reordered_update) == len(update)\n",
    "    sum_middle_pages += int(reordered_update[len(reordered_update) // 2])\n",
    "\n",
    "sum_middle_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
